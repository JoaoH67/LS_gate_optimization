{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a24cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "from State_simulation_Final import State\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.special import comb\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy.integrate as integrate\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "from scipy.stats import norm\n",
    "\n",
    "import qinfer\n",
    "from qinfer import FiniteOutcomeModel\n",
    "from qinfer import Distribution\n",
    "from qinfer import SMCUpdater, UniformDistribution\n",
    "\n",
    "from copy import deepcopy\n",
    "import scipy.linalg as la\n",
    "\n",
    "from qutip import basis, fock, tensor\n",
    "from qutip import rx, ry, rz, sigmax, sigmay, sigmaz, rotation\n",
    "from qutip import destroy, create, num, cnot, qeye\n",
    "from qutip import expect, thermal_dm, ket2dm\n",
    "from qutip import Qobj, QobjEvo, sesolve\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cac5795",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_list = [[]]*4\n",
    "\n",
    "# Each element of this list is an interpolator for 1, 3, 5 or 7 gates, respectively\n",
    "# The interpolator is used to calculate the likelihood of a measurement (gg, ee, eg/ge) for\n",
    "# a given Rabi detuning and a given number of gates\n",
    "\n",
    "# For simplicitly, here we don't simulate with SPAM and depolarizing errors, but this \n",
    "# can easily be done as well (see LS_simulation_Final.ipynb)\n",
    "\n",
    "psi=State([1,0,0,0,0])\n",
    "d_range=np.linspace(0., 1.6, 51)\n",
    "\n",
    "for j in range(4):\n",
    "\n",
    "    probs = psi.detune(2*j+1, Sb=d_range, Rabi=d_range)\n",
    "    interp = RegularGridInterpolator((d_range, d_range), probs, bounds_error=False, fill_value=0.)\n",
    "    interp_list[j]=deepcopy(interp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e437da5",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fda5e0",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694b8f92",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefa0cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(updater, i, mu, sig, cov, optimal_setting):\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(5, 12), dpi=150)\n",
    "    \n",
    "    ax = plt.subplot(411)\n",
    "    plt.scatter(updater.particle_locations[:,0], updater.particle_locations[:,1], c=updater.particle_weights)\n",
    "    plt.axis('equal')\n",
    "    plt.xlabel('Sb')\n",
    "    plt.ylabel('Rabi')\n",
    "\n",
    "    \n",
    "    ax = plt.subplot(412)\n",
    "    steps=np.arange(i+1)\n",
    "    ax.scatter(steps[:-1], 2*optimal_setting+1)\n",
    "    plt.xlabel('step')\n",
    "    plt.ylabel('# of gates')\n",
    "\n",
    "    \n",
    "    ax = plt.subplot(413)\n",
    "    plt.plot(steps, mu)\n",
    "    plt.legend(['$\\mu_\\Omega$', '$\\mu_\\delta$'])\n",
    "    plt.grid()\n",
    "\n",
    "    \n",
    "    ax = plt.subplot(414)\n",
    "    plt.plot(steps, sig)\n",
    "    plt.plot(steps, np.array([np.linalg.det(cov[i]) for i in range(cov.shape[0])])**0.25)\n",
    "    plt.legend(['$\\sigma_\\Omega$', '$\\sigma_\\delta$', '$\\sqrt[4]{|\\Sigma|}$'])\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5285c0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSModel(FiniteOutcomeModel):\n",
    "    \n",
    "    @property\n",
    "    def n_modelparams(self):\n",
    "        # The model parameters (things that you want to optimize over, in this case, the drive power)\n",
    "        return 2\n",
    "    \n",
    "    @property\n",
    "    def is_n_outcomes_constant(self):\n",
    "        return True\n",
    "    def n_outcomes(self, expparams):\n",
    "        return 3\n",
    "    \n",
    "    def are_models_valid(self, modelparams):\n",
    "        \n",
    "        return np.all(np.logical_and(modelparams > 0.2, modelparams < 1.4), axis=1)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def expparams_dtype(self):\n",
    "        return [('n_gates', 'int')]\n",
    "\n",
    "    def likelihood(self, outcomes, modelparams, expparams):\n",
    "        \n",
    "        # Computes the likelihood of an outcome given a modelparam and an expparam (# of gates)\n",
    "        \n",
    "        super(LSModel, self).likelihood(\n",
    "            outcomes, modelparams, expparams)\n",
    "        \n",
    "        expparams=np.squeeze(expparams)\n",
    "        probabilities = interp_list[expparams]((modelparams[:, np.newaxis, 0], \n",
    "                                                  modelparams[:,np.newaxis, 1])).T.reshape(3, -1, 1).real\n",
    "        # Computes the likelihood\n",
    "        \n",
    "\n",
    "        if len(np.shape(outcomes)) == 0:\n",
    "            outcomes = np.array(outcomes)[None]\n",
    "                    \n",
    "        likelihood_array= np.concatenate([\n",
    "            probabilities[np.newaxis, outcomes[idx]]\n",
    "            for idx in range(outcomes.shape[0])\n",
    "        ])\n",
    "        # Generates the likelihood array for every outcome that you want to measure\n",
    "\n",
    "        return likelihood_array\n",
    "\n",
    "    \n",
    "def particle_covariance_mtx(weights, locations):\n",
    "\n",
    "        mu = np.dot(weights, locations)\n",
    "\n",
    "        xs = locations.transpose([1, 0])\n",
    "\n",
    "        ws = weights\n",
    "\n",
    "        cov = (\n",
    "            np.einsum('i,mi,ni', ws, xs, xs)\n",
    "            - np.dot(mu[..., np.newaxis], mu[np.newaxis, ...])\n",
    "        )\n",
    "\n",
    "        assert np.all(np.isfinite(cov))\n",
    "        if not np.all(la.eig(cov)[0] >= 0):\n",
    "            warnings.warn('Numerical error in covariance estimation causing positive semidefinite violation.', ApproximationWarning)\n",
    "\n",
    "        return cov\n",
    "    \n",
    "def expected_variance_decrease(updater, expparams):\n",
    "        \n",
    "        os = np.arange(3) # the possible outcomes, gg, ee, and eg/ge\n",
    "\n",
    "        w_hyp, L, N = updater.hypothetical_update(\n",
    "                os[:-1], \n",
    "                expparams, \n",
    "                return_normalization=True, \n",
    "                return_likelihood=True\n",
    "            )\n",
    "        \n",
    "        # calculates the weights of the particles for each outcome\n",
    "        \n",
    "        w_hyp_last_outcome = (1 - L.sum(axis=0)) * updater.particle_weights[np.newaxis, :]\n",
    "        N = np.concatenate([N[:,:,0], np.sum(w_hyp_last_outcome[np.newaxis,:,:], axis=2)], axis=0)\n",
    "        w_hyp_last_outcome = w_hyp_last_outcome / N[-1,:,np.newaxis]\n",
    "        w_hyp = np.concatenate([w_hyp, w_hyp_last_outcome[np.newaxis,:,:]], axis=0)\n",
    "\n",
    "        \n",
    "        cov = sum((np.linalg.det(particle_covariance_mtx(w_hyp[i,0], updater.particle_locations)))**0.25*N[i] for i in os)\n",
    "        # calculates the expected covariance matrix after this measurement\n",
    "        \n",
    "        sig = (np.linalg.det(updater.est_covariance_mtx()))**0.25\n",
    "\n",
    "        return sig-cov\n",
    "\n",
    "\n",
    "def power2rabi(x, logpower):\n",
    "    \n",
    "    if logpower:\n",
    "        \n",
    "        # We don't now the precise relation between laser power and Rabi frequency, so here\n",
    "        # we define some function that could be some power-to-Rabi relation. We choose to work here\n",
    "        # with this log function because it seems to be qualitatively similar to the behavior of the power-to-Rabi\n",
    "        # relation in the actual quantum computer.\n",
    "        # The only requirement for this function is that at power=optimal power, Rabi=1\n",
    "        \n",
    "        return np.array([[np.log2(x[0]+1), x[1]]])\n",
    "    else:\n",
    "        return np.array([[x[0], x[1]]])\n",
    "    \n",
    "def measurement_loop(n_meas, n_shots_per_meas, model, updater, meas_settings, modelparams, \n",
    "                     thresh=None, plot_distributions=None, logpower=None):\n",
    "    \"\"\"\n",
    "    \n",
    "    This program takes an updater with a particle distribution that follows a uniform distribution over a\n",
    "    specified range. At every step in range(n_meas) (or until it stops), it finds what is the best meas setting\n",
    "    to use (how many gates to apply), simulates a measurement with that setting and with the \"actual\" rabi\n",
    "    frequency, and with the outcome of that simulated measurement updates the position of the particles,\n",
    "    reducing the variance of the distribution.\n",
    "    \n",
    "    \n",
    "    :model: where we specify the outcomes, their likelihoods, their parameters, etc. (see LSModel above)\n",
    "    :updater: the object that contains information about the particle locations and weights\n",
    "    :meas_settings: whether we apply 1,3,5,7 gates, represented by an array [0,1,2,3]\n",
    "    :modelparams: the \"actual\" values we want to obtain, for simulation purposes only, a list with a single value\n",
    "    :n_meas, n_shots_per_meas: int's\n",
    "    :thresh: float, the value of the particle distribution variance at which we stop the Bayesian update\n",
    "    :plot_distributions: bool, in case you want to see the particle distribution and measurement outcomes at each step\n",
    "    :logpower: bool, in case you want to use some power-to-Rabi relation that is not the trivial one (Rabi=power)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    particle_locations=np.zeros((n_meas, 1000))\n",
    "    particle_weights=np.zeros((n_meas, 1000))\n",
    "\n",
    "    optimal_setting = np.zeros(n_meas)\n",
    "    ydata = np.zeros((n_meas,n_shots_per_meas))\n",
    "    mu = np.zeros((n_meas+1, model.n_modelparams))\n",
    "    sig = np.zeros((n_meas+1, model.n_modelparams))\n",
    "    \n",
    "    mu[0] = updater.est_mean()\n",
    "    sig[0] = variance(updater.particle_locations, updater.particle_weights)\n",
    "\n",
    "    for i in tqdm(range(n_meas)):\n",
    "        info_gain = [expected_variance_decrease(updater, np.array([meas_settings[i]])) \n",
    "                     for i in range(len(meas_settings))]\n",
    "\n",
    "        opt_meas_set = np.array([meas_settings[np.argmax(info_gain)]]) \n",
    "        # Chooses the one that will minimize the variance the most\n",
    "        \n",
    "        datum = np.squeeze(model.simulate_experiment(power2rabi(modelparams, logpower),\n",
    "                                                     opt_meas_set, repeat=n_shots_per_meas))\n",
    "        # Simulates an experiment with the Rabi frequency given by the conversion, which the \n",
    "        # likelihood function doesn't \"know\"\n",
    "        \n",
    "        \n",
    "        if plot_distributions:\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.hist(updater.particle_locations[:,0]*mu[i,0]/mu[0,0], weights=updater.particle_weights)\n",
    "            print(np.unique(datum, return_counts=True))\n",
    "        \n",
    "        for d in datum:\n",
    "            updater.update(d, opt_meas_set)\n",
    "            # updates the weights of the particles\n",
    "\n",
    "        ydata[i] = datum\n",
    "        optimal_setting[i] = opt_meas_set[0]\n",
    "\n",
    "        mu[i+1] = mu[i]*updater.est_mean()\n",
    "        \n",
    "        sig[i+1] = variance(updater.particle_locations, updater.particle_weights)\n",
    "        \n",
    "        modelparams/=updater.est_mean()\n",
    "        # updates the power of the next measurement, assuming that the relation between\n",
    "        # Rabi and power is linear (because the optimizer doesn't \"know\" the power-to-Rabi relation)\n",
    "        \n",
    "        updater.particle_locations/=updater.est_mean()\n",
    "        # updates the particle distribution, bringing the average to 0\n",
    "        \n",
    "        \n",
    "        if thresh!=None:\n",
    "            if np.all(np.sqrt(sig[i+1])<thresh):\n",
    "                break # stops updating when variance reaches threshold\n",
    "    \n",
    "    mu/=mu[0]\n",
    "    updater.particle_locations*=mu[i+1]\n",
    "\n",
    "    ydata = 1-ydata.mean(axis=1)\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "    mu = mu[:i+1]\n",
    "    sig = sig[:i+1]\n",
    "    optimal_setting = optimal_setting[:i]\n",
    "    ydata = ydata[:i+1]\n",
    "    particle_locations=particle_locations[:i+1]\n",
    "    particle_weights=particle_weights[:i+1]\n",
    "    \n",
    "    \n",
    "    return updater, i, mu, sig, optimal_setting, ydata, modelparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc709753",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = LSModel()\n",
    "modelparams = np.array([1.3, 0.8]) # The values at which the measurement outcomes will be generated\n",
    "params_0=np.copy(modelparams)\n",
    "\n",
    "prior = UniformDistribution([[.2, 1.4], [.2, 1.4]])\n",
    "# We can start with a smaller range for the prior of the Rabi frequency, depending on \n",
    "# our current knowledge of possible laser powers.\n",
    "\n",
    "# Notice that the range for the SPAM and depolarizing values here is 0. This is because\n",
    "# we don't want the optimizer to learn them, as in the real experiment. We can see that\n",
    "# the optimization works even if the SPAM and depolarizing values that the optimizer assumes\n",
    "# is different from the values at which the measurement data is generated\n",
    "\n",
    "updater = SMCUpdater(model, 1000, prior)\n",
    "# Creates an updater with 1000 particles\n",
    "\n",
    "meas_settings = np.arange(4).astype(int) # 0, 1, 2, 3 corresponds to 1, 3, 5, 7 gates respectively\n",
    "\n",
    "n_meas = 10\n",
    "\n",
    "n_shots_per_meas = 100\n",
    "\n",
    "thresh=0.01\n",
    "\n",
    "updater, i, mu, sig, optimal_setting, ydata, params = measurement_loop(\n",
    "    n_meas, n_shots_per_meas, model, deepcopy(updater),\n",
    "    meas_settings, modelparams, thresh, plot_distributions=False)\n",
    "\n",
    "plot(updater, i, mu, np.sqrt(sig), optimal_setting, params_0)\n",
    "\n",
    "print(\"Finished in {} steps with values Sb={:.4f}$\\pm${:.4f}, Rabi={:.4f}$\\pm${:.4f}\".format(\n",
    "    i-1, mu[-1,0], sig[-1,0], mu[-1,1], sig[-1,1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
