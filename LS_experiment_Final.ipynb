{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be36e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.interpolate import interp1d\n",
    "from State_simulation_Final import State\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "import zmq\n",
    "context = zmq.Context()\n",
    "\n",
    "import qinfer\n",
    "from qinfer import FiniteOutcomeModel\n",
    "from qinfer import Distribution\n",
    "from qinfer import SMCUpdater, UniformDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decb3a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADDR = \"tcp://vidyut.physik.uni-mainz.de:55551\"\n",
    "\n",
    "socket = context.socket(zmq.REQ)\n",
    "socket.connect(ADDR)\n",
    "\n",
    "def json_rpc_request(method:str, params, id=None) -> dict:\n",
    "    if id is None:\n",
    "        id=1\n",
    "    request={\n",
    "        \"jsonrpc\":\"2.0\",\n",
    "        \"method\":method,\n",
    "        \"id\": id,\n",
    "    }\n",
    "    if params is not None:\n",
    "        request[\"params\"]=params\n",
    "    return request\n",
    "\n",
    "def parse_rpc_reply(reply:dict)->any:\n",
    "    assert reply[\"jsonrpc\"]=='2.0'\n",
    "    if \"error\" in reply:\n",
    "        raise Exception(reply[\"error\"])\n",
    "    else:\n",
    "        return reply[\"id\"], reply[\"result\"]\n",
    "\n",
    "def send_recv_rpc_message(method:str, params, id=None)->any:\n",
    "    request = json_rpc_request(method, params, id)\n",
    "    request_id=request[\"id\"]\n",
    "    socket.send_json(request)\n",
    "    print(\"Waiting for reply...\")\n",
    "    reply = socket.recv_json()\n",
    "    \n",
    "    reply_id, result = parse_rpc_reply(reply)\n",
    "    assert request_id == reply_id, \"Ids of request (%s) and reply (%s) do not match.\"% (request_id, reply_id)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4fd437",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_list = [[]]*4\n",
    "\n",
    "psi=State([1,0,0,0,0])\n",
    "d_range=np.linspace(0, 1.4, 51)\n",
    "\n",
    "for j in range(4):\n",
    "    \n",
    "    psi=State([1,0,0,0,0]) #creates the state |gg>\n",
    "    \n",
    "    probs = psi.detune(2*j+1, Rabi=d_range, unitary=True, factor_SPAM=0.008, factor_dep=0.005)\n",
    "\n",
    "    \n",
    "    interp = interp1d(d_range, probs, kind='cubic', bounds_error=False, fill_value=0., axis=0) \n",
    "    \n",
    "    interp_list[j]=deepcopy(interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff09e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(updater, i, mu, sig, optimal_setting, modelparams):\n",
    "    \n",
    "    # Just a plotting function\n",
    "    \n",
    "    plt.figure(figsize=(5, 12), dpi=150)\n",
    "    \n",
    "    ax = plt.subplot(411)\n",
    "    ax.hist(updater.particle_locations[:,0], weights=updater.particle_weights)\n",
    "    ax.set_xlabel('Rabi')\n",
    "\n",
    "    pi4 = (optimal_setting>3).astype(int)\n",
    "    \n",
    "    ax = plt.subplot(412)\n",
    "    steps=np.arange(i+1)\n",
    "    ax.scatter(steps[:-1], 2*optimal_setting+1)\n",
    "\n",
    "\n",
    "    plt.xlabel('step')\n",
    "    plt.ylabel('# of gates')\n",
    "\n",
    "    ax = plt.subplot(413)\n",
    "\n",
    "    plt.plot(steps, mu[:,0])\n",
    "    plt.legend(['$\\mu_\\Omega$'])\n",
    "    plt.xscale('log')\n",
    "    plt.grid()\n",
    "\n",
    "    ax = plt.subplot(414)\n",
    "    \n",
    "    plt.plot(steps, sig[:,0]*np.sqrt(2/np.pi))\n",
    "    plt.plot(steps, np.abs(mu[:,0]*np.sqrt(1/(1-0.36))-modelparams[0]/50))\n",
    "    plt.legend(['$\\sigma_\\Omega$', '$|\\mu_\\Omega-\\mu_{opt}|$'])\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195cb296",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSModel(FiniteOutcomeModel):\n",
    "    \n",
    "    @property\n",
    "    def n_modelparams(self):\n",
    "        # The model parameters (number of things the qubit population depends over, \n",
    "        # in this case, the drive power, SPAM and depolarizing factors)\n",
    "        return 3\n",
    "    \n",
    "    @property\n",
    "    def is_n_outcomes_constant(self):\n",
    "        return True\n",
    "    def n_outcomes(self, expparams):\n",
    "        return 3 #gg, ee, eg+ge\n",
    "    \n",
    "    def are_models_valid(self, modelparams):\n",
    "        \n",
    "        return np.logical_and(np.logical_and(modelparams[:,0] > 0.2, modelparams[:,0] < 1.4), \n",
    "                              np.logical_and(modelparams[:,1] > 0., modelparams[:,1] < 0.02),\n",
    "                              np.logical_and(modelparams[:,2] > 0., modelparams[:,2] < 0.005))\n",
    "    \n",
    "        # The last two just correspond to the limits of the interpolation range\n",
    "        # The first one just assumes that we know that our laser power is not too low (so greater than 0.2)\n",
    "        # and has to be limited above by 1.4 so that the likelihood for a single LS gate\n",
    "        # in the first step is a monotonic function, that is, it will not create a multimodal\n",
    "        # particle distribution already in step 2.\n",
    "\n",
    "\n",
    "    @property\n",
    "    def expparams_dtype(self):\n",
    "        return [('n_gates', 'int')]\n",
    "\n",
    "    def likelihood(self, outcomes, modelparams, expparams):\n",
    "        \n",
    "        # Computes the likelihood of an outcome given a modelparam and an expparam (# of gates)\n",
    "        \n",
    "        super(LSModel, self).likelihood(\n",
    "            outcomes, modelparams, expparams)\n",
    "        \n",
    "        expparams=np.squeeze(expparams)\n",
    "        probabilities = interp_list[expparams]((modelparams[:, np.newaxis, 0], \n",
    "                                                modelparams[:, np.newaxis, 1], \n",
    "                                                modelparams[:, np.newaxis, 2])).T.reshape(3, -1, 1).real\n",
    "        # Computes the likelihood\n",
    "        \n",
    "\n",
    "        if len(np.shape(outcomes)) == 0:\n",
    "            outcomes = np.array(outcomes)[None]\n",
    "                    \n",
    "        likelihood_array= np.concatenate([\n",
    "            probabilities[np.newaxis, outcomes[idx]]\n",
    "            for idx in range(outcomes.shape[0])\n",
    "        ])\n",
    "        # Generates the likelihood array for every outcome that you want to measure\n",
    "\n",
    "        return likelihood_array\n",
    "\n",
    "    \n",
    "def variance(positions, weights): # Usual variance formula\n",
    "    \n",
    "    mean = np.dot(weights, positions)\n",
    "    return np.dot(weights, (positions-mean)**2)\n",
    "\n",
    "def expected_variance_decrease(updater, expparams):\n",
    "        \n",
    "        os = np.arange(3) # the possible outcomes, gg, ee, and eg/ge\n",
    "\n",
    "        w_hyp, L, N = updater.hypothetical_update(\n",
    "                os[:-1], \n",
    "                expparams, \n",
    "                return_normalization=True, \n",
    "                return_likelihood=True\n",
    "            )\n",
    "        \n",
    "        # calculates the weights of the particles for each outcome\n",
    "        \n",
    "        w_hyp_last_outcome = (1 - L.sum(axis=0)) * updater.particle_weights[np.newaxis, :]\n",
    "        N = np.concatenate([N[:,:,0], np.sum(w_hyp_last_outcome[np.newaxis,:,:], axis=2)], axis=0)\n",
    "        w_hyp_last_outcome = w_hyp_last_outcome / N[-1,:,np.newaxis]\n",
    "        w_hyp = np.concatenate([w_hyp, w_hyp_last_outcome[np.newaxis,:,:]], axis=0)\n",
    "\n",
    "        \n",
    "        sig_exp = sum(variance(updater.particle_locations, w_hyp[i,0])*N[i] for i in os)\n",
    "        # calculates the expected variance after this measurement\n",
    "        \n",
    "        sig = variance(updater.particle_locations, updater.particle_weights)\n",
    "        # the current variance of the particle distribution\n",
    "        \n",
    "        return (sig-sig_exp)[0]\n",
    "\n",
    "\n",
    "def power2rabi(x, logpower):\n",
    "    \n",
    "    if logpower:\n",
    "        \n",
    "        # We don't now the precise relation between laser power and Rabi frequency, so here\n",
    "        # we define some function that could be some power-to-Rabi relation. We choose to work here\n",
    "        # with this log function because it seems to be qualitatively similar to the behavior of the power-to-Rabi\n",
    "        # relation in the actual quantum computer.\n",
    "        # The only requirement for this function is that at power=optimal power, Rabi=1\n",
    "        \n",
    "        return np.array([[np.log2(x[0]+1), x[1], x[2]]])\n",
    "    else:\n",
    "        return np.array([[x[0], x[1], x[2]]])\n",
    "    \n",
    "def measurement_loop(n_meas, n_shots_per_meas, model, updater, meas_settings, modelparams, \n",
    "                     thresh=None, plot_distributions=None, logpower=None):\n",
    "    \"\"\"\n",
    "    \n",
    "    This program takes an updater with a particle distribution that follows a uniform distribution over a\n",
    "    specified range. At every step in range(n_meas) (or until it stops), it finds what is the best meas setting\n",
    "    to use (how many gates to apply), simulates a measurement with that setting and with the \"actual\" rabi\n",
    "    frequency, and with the outcome of that simulated measurement updates the position of the particles,\n",
    "    reducing the variance of the distribution.\n",
    "    \n",
    "    \n",
    "    :model: where we specify the outcomes, their likelihoods, their parameters, etc. (see LSModel above)\n",
    "    :updater: the object that contains information about the particle locations and weights\n",
    "    :meas_settings: whether we apply 1,3,5,7 gates, represented by an array [0,1,2,3]\n",
    "    :modelparams: the \"actual\" values we want to obtain, for simulation purposes only, a list with a single value\n",
    "    :n_meas, n_shots_per_meas: int's\n",
    "    :thresh: float, the value of the particle distribution variance at which we stop the Bayesian update\n",
    "    :plot_distributions: bool, in case you want to see the particle distribution and measurement outcomes at each step\n",
    "    :logpower: bool, in case you want to use some power-to-Rabi relation that is not the trivial one (Rabi=power)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    particle_locations=np.zeros((n_meas, 1000))\n",
    "    particle_weights=np.zeros((n_meas, 1000))\n",
    "\n",
    "    optimal_setting = np.zeros(n_meas)\n",
    "    ydata = np.zeros((n_meas,n_shots_per_meas))\n",
    "    mu = np.zeros((n_meas+1, model.n_modelparams))\n",
    "    sig = np.zeros((n_meas+1, model.n_modelparams))\n",
    "    \n",
    "    mu[0] = updater.est_mean()\n",
    "    sig[0] = variance(updater.particle_locations, updater.particle_weights)\n",
    "\n",
    "    for i in tqdm(range(n_meas)):\n",
    "        info_gain = [expected_variance_decrease(updater, np.array([meas_settings[i]])) \n",
    "                     for i in range(len(meas_settings))]\n",
    "\n",
    "        opt_meas_set = np.array([meas_settings[np.argmax(info_gain)]]) \n",
    "        # Chooses the one that will minimize the variance the most\n",
    "        \n",
    "        shots = send_recv_rpc_message(method = \"bell_state_calibration\", \n",
    "                          params={\"shots\": n_shots_per_meas, \"gates\": int(2*np.argmax(info_gain)+1),\n",
    "                                  \"global_vars\":{\"Glightforce.lightforce_s::WobblePower\": modelparams[0]}})\n",
    "\n",
    "        gg = shots[0]*n_shots_per_meas\n",
    "        ee = shots[3]*n_shots_per_meas\n",
    "\n",
    "        datum = [1]*int(ee)+[0]*int(gg)+[2]*(n_shots_per_meas-int(gg)-int(ee))\n",
    "        datum = np.array(datum)\n",
    "        random.shuffle(datum) # Generates individual shot data from received qubit population data \n",
    "        \n",
    "        \n",
    "        if plot_distributions:\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.hist(updater.particle_locations[:,0]*mu[i,0]/mu[0,0], weights=updater.particle_weights)\n",
    "            print(np.unique(datum, return_counts=True))\n",
    "        \n",
    "        for d in datum:\n",
    "            updater.update(d, opt_meas_set)\n",
    "            # updates the weights of the particles\n",
    "\n",
    "        ydata[i] = datum\n",
    "        optimal_setting[i] = opt_meas_set[0]\n",
    "\n",
    "        mu[i+1,0] = mu[i,0]*updater.est_mean()[0]\n",
    "        mu[i+1,1:] = updater.est_mean()[1:]\n",
    "        \n",
    "        sig[i+1] = variance(updater.particle_locations, updater.particle_weights)\n",
    "        \n",
    "        modelparams[0]/=updater.est_mean()[0]\n",
    "        # updates the power of the next measurement, assuming that the relation between\n",
    "        # Rabi and power is linear (because the optimizer doesn't \"know\" the power-to-Rabi relation)\n",
    "        \n",
    "        updater.particle_locations[:,0]/=updater.est_mean()[0]\n",
    "        # updates the particle distribution, bringing the average to 0\n",
    "        \n",
    "        \n",
    "        if thresh!=None:\n",
    "            if np.all(np.sqrt(sig[i+1])<thresh):\n",
    "                break # stops updating when variance reaches threshold\n",
    "    \n",
    "    mu[:,0]/=mu[0,0]\n",
    "    updater.particle_locations[:,0]*=mu[i+1,0]\n",
    "\n",
    "    ydata = 1-ydata.mean(axis=1)\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "    mu = mu[:i+1]\n",
    "    sig = sig[:i+1]\n",
    "    optimal_setting = optimal_setting[:i]\n",
    "    ydata = ydata[:i+1]\n",
    "    particle_locations=particle_locations[:i+1]\n",
    "    particle_weights=particle_weights[:i+1]\n",
    "    \n",
    "    \n",
    "    return updater, i, mu, sig, optimal_setting, ydata, modelparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe542ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = LSModel()\n",
    "params_0=np.copy(modelparams)\n",
    "\n",
    "prior = UniformDistribution([[.2, 1.4]])\n",
    "# We can start with a smaller range for the prior of the Rabi frequency, depending on \n",
    "# our current knowledge of possible laser powers.\n",
    "\n",
    "updater = SMCUpdater(model, 1000, prior)\n",
    "# Creates an updater with 1000 particles\n",
    "\n",
    "meas_settings = np.arange(4).astype(int) # 0, 1, 2, 3 corresponds to 1, 3, 5, 7 gates respectively\n",
    "\n",
    "n_meas = 10\n",
    "\n",
    "n_shots_per_meas = 100\n",
    "\n",
    "thresh=0.01\n",
    "\n",
    "updater, i, mu, sig, optimal_setting, ydata, params = measurement_loop(\n",
    "    n_meas, n_shots_per_meas, model, deepcopy(updater),\n",
    "    meas_settings, modelparams, thresh, plot_distributions=False)\n",
    "\n",
    "plot(updater, i, mu, np.sqrt(sig), optimal_setting, params_0)\n",
    "\n",
    "print(\"Finished in {} steps with value power={:.4f}\\pm{:.4f}, SPAM={:.4f}\\pm{:.4f}\".format(\n",
    "    i, mu[-1,0], sig[-1,0]/mu[-1,0]*params[0], mu[-1,1], sig[-1,1]))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
